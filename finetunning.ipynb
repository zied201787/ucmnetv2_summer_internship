{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-20T23:06:22.482279Z",
     "start_time": "2025-07-20T23:06:22.461458Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "from scipy import ndimage\n",
    "import os\n",
    "from archs_ucm_v2 import UCM_NetV2\n",
    "from engineucm1 import train_one_epoch, val_one_epoch, test_one_epoch\n",
    "from loader import isic_loader\n",
    "from losses import GT_BceDiceLoss_new2\n",
    "from utils_ucm import get_logger\n",
    "from configs.config_setting import setting_config\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "from scipy import ndimage\n",
    "from sklearn.model_selection import KFold ,train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "\n"
   ],
   "id": "cbbea35880804889",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-20T23:06:42.590733Z",
     "start_time": "2025-07-20T23:06:42.576406Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def dataset_normalized(imgs):\n",
    "    imgs_std = np.std(imgs)\n",
    "    imgs_mean = np.mean(imgs)\n",
    "    imgs_normalized = (imgs - imgs_mean) / imgs_std\n",
    "    for i in range(imgs.shape[0]):\n",
    "        imgs_normalized[i] = (imgs_normalized[i] - np.min(imgs_normalized[i])) / (np.max(imgs_normalized[i]) - np.min(imgs_normalized[i]))\n",
    "    return imgs_normalized\n",
    "\n",
    "class ISICKFoldDataset(Dataset):\n",
    "    def __init__(self, data, mask, train=True, augment=True):\n",
    "        super().__init__()\n",
    "        self.data = dataset_normalized(data.astype(np.float32))\n",
    "        self.mask = (mask.astype(np.float32) / 255.0)\n",
    "        self.train = train\n",
    "        self.augment = augment\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.data[idx]\n",
    "        seg = self.mask[idx]\n",
    "\n",
    "        if self.train and self.augment:\n",
    "            if random.random() > 0.7:\n",
    "                img, seg = self.random_rot_flip(img, seg)\n",
    "            if random.random() > 0.7:\n",
    "                img, seg = self.random_rotate(img, seg)\n",
    "\n",
    "        img = torch.tensor(img, dtype=torch.float32).permute(2, 0, 1)\n",
    "        seg = torch.tensor(seg, dtype=torch.float32)\n",
    "        if seg.ndim == 2:\n",
    "            seg = seg.unsqueeze(0)\n",
    "        elif seg.ndim == 3:\n",
    "            seg = seg.permute(2, 0, 1)\n",
    "\n",
    "        return img, seg\n",
    "\n",
    "    def random_rot_flip(self, img, label):\n",
    "        k = np.random.randint(0, 4)\n",
    "        img = np.rot90(img, k)\n",
    "        label = np.rot90(label, k)\n",
    "        axis = np.random.randint(0, 2)\n",
    "        img = np.flip(img, axis=axis).copy()\n",
    "        label = np.flip(label, axis=axis).copy()\n",
    "        return img, label\n",
    "\n",
    "    def random_rotate(self, img, label):\n",
    "        angle = np.random.randint(20, 80)\n",
    "        img = ndimage.rotate(img, angle, order=0, reshape=False)\n",
    "        label = ndimage.rotate(label, angle, order=0, reshape=False)\n",
    "        return img, label\n"
   ],
   "id": "30af3be8390d6149",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-20T23:06:44.744683Z",
     "start_time": "2025-07-20T23:06:44.735109Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize metric histories for this fold\n",
    "train_metrics_history = {'loss': [], 'f1': [], 'acc': [], 'se': [], 'sp': []}\n",
    "val_metrics_history = {'loss': [], 'f1': [], 'acc': [], 'se': [], 'sp': []}\n",
    "test_metrics_history = {'loss': [], 'f1': [], 'acc': [], 'se': [], 'sp': []}\n"
   ],
   "id": "c186b890a1715cd7",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-20T23:08:02.828569Z",
     "start_time": "2025-07-20T23:06:47.324418Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ===== SAFE LOOKAHEAD WRAPPER =====\n",
    "merged_data=np.load('merged_data2017.npy')\n",
    "merged_mask=np.load('merged_mask2017.npy')\n",
    "print(merged_data.shape)\n",
    "k=5\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "# ===== SETUP =====\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "gpu_ids = [0] if torch.cuda.is_available() else []\n",
    "\n",
    "config = setting_config()\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# === Load original ISIC2017 test set (not part of merged data) ===\n",
    "isic2017_test_dataset = isic_loader(path_Data='./data/ISIC2017/', train=False, Test=True)\n",
    "isic2017_test_loader = DataLoader(isic2017_test_dataset, batch_size=1, shuffle=False, num_workers=config.num_workers)\n",
    "\n",
    "# === Split merged dataset into train_val (1400) and test (600) ===\n",
    "train_val_data, test_data, train_val_mask, test_mask = train_test_split(\n",
    "    merged_data, merged_mask, test_size=600, random_state=42)\n",
    "\n",
    "test_set = ISICKFoldDataset(test_data, test_mask, train=False)\n",
    "test_loader = DataLoader(test_set, batch_size=1, shuffle=False, num_workers=config.num_workers)\n",
    "\n",
    "# === Manual 5-Fold with fixed 150-validation split ===\n",
    "num_folds = 5\n",
    "val_size = 150\n",
    "all_indices = np.arange(train_val_data.shape[0])\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(all_indices)\n",
    "\n",
    "folds = []\n",
    "for i in range(num_folds):\n",
    "    val_start = i * val_size\n",
    "    val_end = val_start + val_size\n",
    "    val_idx = all_indices[val_start:val_end]\n",
    "    train_idx = np.setdiff1d(all_indices, val_idx)\n",
    "    folds.append((train_idx, val_idx))\n",
    "\n",
    "# === Training Loop ===\n",
    "fold = 1\n",
    "for train_idx, val_idx in folds:\n",
    "    print(f\"\\n===== üîÅ Fold {fold}/{num_folds} =====\")\n",
    "\n",
    "    train_set = ISICKFoldDataset(train_val_data[train_idx], train_val_mask[train_idx], train=True)\n",
    "    val_set = ISICKFoldDataset(train_val_data[val_idx], train_val_mask[val_idx], train=False)\n",
    "\n",
    "    train_loader = DataLoader(train_set, batch_size=config.batch_size, shuffle=True, num_workers=config.num_workers)\n",
    "    val_loader = DataLoader(val_set, batch_size=1, shuffle=False, num_workers=config.num_workers)\n",
    "\n",
    "    model = UCM_NetV2(1, 3, False)\n",
    "    state_dict = torch.load('results/fine70/ultra__Friday_11_July_2025_12h_28m_08s/checkpoints_GT_BceDiceLoss_new2/best.pth', map_location='cpu')\n",
    "    model.load_state_dict(state_dict)\n",
    "    model = torch.nn.DataParallel(model.to(device), device_ids=gpu_ids)\n",
    "\n",
    "    criterion = GT_BceDiceLoss_new2().to(device)\n",
    "    optimizer = AdamW(model.parameters(), lr=2e-4, weight_decay=config.weight_decay)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=30, eta_min=1e-6)\n",
    "    scaler = torch.cuda.amp.GradScaler() if config.amp else None\n",
    "\n",
    "    log_dir = os.path.join(config.work_dir, f'log_fold_{fold}')\n",
    "    checkpoint_dir = os.path.join(config.work_dir, f'checkpoints_fold_{fold}')\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    logger = get_logger(f'fold_{fold}', log_dir)\n",
    "\n",
    "    best_dice = 0.0\n",
    "    min_loss = float('inf')\n",
    "    start_epoch = 1\n",
    "    num_fine_tune_epochs = 15\n",
    "\n",
    "    for epoch in range(start_epoch, start_epoch + num_fine_tune_epochs):\n",
    "        print(f\"\\nüî• Fine-tuning Epoch {epoch}/{start_epoch + num_fine_tune_epochs - 1} (Fold {fold})\")\n",
    "\n",
    "        # TRAIN (assuming train_one_epoch returns loss, metrics dict)\n",
    "        train_loss, train_metrics = train_one_epoch(train_loader, model, criterion, optimizer, scheduler,\n",
    "                                                   epoch, logger, config, scaler=scaler, epoch_num=num_fine_tune_epochs)\n",
    "        for key in train_metrics_history:\n",
    "            train_metrics_history[key].append(train_metrics[key] if key != 'loss' else train_loss)\n",
    "\n",
    "        # VALIDATION\n",
    "        val_loss, val_metrics = val_one_epoch(val_loader, model, criterion, epoch,\n",
    "                                              logger, config, epoch_num=num_fine_tune_epochs)\n",
    "        for key in val_metrics_history:\n",
    "            val_metrics_history[key].append(val_metrics[key] if key != 'loss' else val_loss)\n",
    "\n",
    "        print(f\"Validation - Loss: {val_loss:.4f}, Dice: {val_metrics['f1']:.4f}, Sensitivity: {val_metrics['se']:.4f}\")\n",
    "\n",
    "        # TEST (run every epoch)\n",
    "        test_loss, test_metrics = test_one_epoch(test_loader, model, criterion, logger,\n",
    "                                                 config, epoch=epoch, epoch_num=num_fine_tune_epochs)\n",
    "        for key in test_metrics_history:\n",
    "            test_metrics_history[key].append(test_metrics[key] if key != 'loss' else test_loss)\n",
    "\n",
    "        print(f\"Test - Loss: {test_loss:.4f}, Dice: {test_metrics['f1']:.4f}, Sensitivity: {test_metrics['se']:.4f}\")\n",
    "\n",
    "        # Save best model (optional, based on val_loss)\n",
    "        if val_loss < min_loss:\n",
    "            min_loss = val_loss\n",
    "            print(f\"‚úÖ New minimum validation loss: {val_loss:.4f} ‚Äî model saved.\")\n",
    "            torch.save(model.module.state_dict(), os.path.join(checkpoint_dir, 'fine_tuned_min_loss.pth'))\n",
    "\n",
    "\n",
    "        fold += 1\n"
   ],
   "id": "4d981ba3bc22ca4e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 256, 256, 3)\n",
      "Using device: cuda\n",
      "\n",
      "===== üîÅ Fold 1/5 =====\n",
      "\n",
      "üî• Fine-tuning Epoch 1/15 (Fold 1)\n",
      "train: epoch 1, iter:0, loss: 5.2229, lr: 0.000200\n",
      "train: epoch 1, iter:20, loss: 2.5528, lr: 0.000200\n",
      "train: epoch 1, iter:40, loss: 2.5093, lr: 0.000200\n",
      "train: epoch 1, iter:60, loss: 2.4621, lr: 0.000200\n",
      "train: epoch 1, iter:80, loss: 2.4167, lr: 0.000200\n",
      "train: epoch 1, iter:100, loss: 2.3420, lr: 0.000200\n",
      "train: epoch 1, iter:120, loss: 2.4154, lr: 0.000200\n",
      "train: epoch 1, iter:140, loss: 2.4463, lr: 0.000200\n",
      "[Train] Epoch 1 | Loss: 2.4692 | Dice: 0.0000 | Acc: 0.8154 | SE: 0.0000 | SP: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 150/150 [00:02<00:00, 57.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val epoch: 1, loss: 2.1050, miou: 0.8726, f1_or_dsc: 0.9320, accuracy: 0.9735, specificity: 0.9869, sensitivity: 0.9190, confusion_matrix: [[7783580, 103360], [157338, 1786122]]\n",
      "0.9734804280597967 0.8726326692132808 0.9190423265717231 0.9868947906284329\n",
      "Validation - Loss: 2.1050, Dice: 0.9320, Sensitivity: 0.9190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 600/600 [00:09<00:00, 62.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test of best model, loss: 1.2640,miou: 0.8567163232583271, f1_or_dsc: 0.9228295270813227, accuracy: 0.970236078898112,                 specificity: 0.9872368931253673, sensitivity: 0.9011501257112952, confusion_matrix: [[31153433   402755]\n",
      " [  767610  6997802]]\n",
      "Test - Loss: 1.2640, Dice: 0.9228, Sensitivity: 0.9012\n",
      "‚úÖ New minimum validation loss: 2.1050 ‚Äî model saved.\n",
      "\n",
      "üî• Fine-tuning Epoch 2/15 (Fold 2)\n",
      "train: epoch 2, iter:0, loss: 1.8607, lr: 0.000199\n",
      "train: epoch 2, iter:20, loss: 2.3067, lr: 0.000199\n",
      "train: epoch 2, iter:40, loss: 2.4209, lr: 0.000199\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[35], line 79\u001B[0m\n\u001B[0;32m     76\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124müî• Fine-tuning Epoch \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mstart_epoch\u001B[38;5;250m \u001B[39m\u001B[38;5;241m+\u001B[39m\u001B[38;5;250m \u001B[39mnum_fine_tune_epochs\u001B[38;5;250m \u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;241m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m (Fold \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfold\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m)\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     78\u001B[0m \u001B[38;5;66;03m# TRAIN (assuming train_one_epoch returns loss, metrics dict)\u001B[39;00m\n\u001B[1;32m---> 79\u001B[0m train_loss, train_metrics \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_one_epoch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscheduler\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     80\u001B[0m \u001B[43m                                           \u001B[49m\u001B[43mepoch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogger\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscaler\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mscaler\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepoch_num\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_fine_tune_epochs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     81\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m key \u001B[38;5;129;01min\u001B[39;00m train_metrics_history:\n\u001B[0;32m     82\u001B[0m     train_metrics_history[key]\u001B[38;5;241m.\u001B[39mappend(train_metrics[key] \u001B[38;5;28;01mif\u001B[39;00m key \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mloss\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m train_loss)\n",
      "File \u001B[1;32m~\\.conda\\envs\\jupyter_env\\UCMV2-Net-main\\UCMV2-Net-main\\engineucm1.py:53\u001B[0m, in \u001B[0;36mtrain_one_epoch\u001B[1;34m(train_loader, model, criterion, optimizer, scheduler, epoch, logger, config, scaler, epoch_num)\u001B[0m\n\u001B[0;32m     50\u001B[0m     loss\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[0;32m     51\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[1;32m---> 53\u001B[0m loss_list\u001B[38;5;241m.\u001B[39mappend(\u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mitem\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m     55\u001B[0m \u001B[38;5;66;03m# Collect predictions and targets for metrics\u001B[39;00m\n\u001B[0;32m     56\u001B[0m out \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39msigmoid(out)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "e3c80cf69a77941"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "79f882a7477f823e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "644cb1103809b06f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "epochs = range(1, len(train_metrics_history['f1']) + 1)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epochs, train_metrics_history['loss'], label='Train Loss', color='blue')\n",
    "plt.plot(epochs, test_metrics_history['loss'], label='Test Loss', color='green')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('acc')\n",
    "plt.title('Loss per Epoch')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "6e43540e8f18ecdb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "from archs_ucm_v2 import UCM_NetV2\n",
    "from engineucm1 import train_one_epoch, val_one_epoch, test_one_epoch\n",
    "from loader import isic_loader\n",
    "from losses import GT_BceDiceLoss_new2\n",
    "from utils_ucm import get_logger\n",
    "from configs.config_setting import setting_config\n",
    "\n",
    "# -------- Setup -------- #\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "gpu_ids = [0] if torch.cuda.is_available() else []\n",
    "\n",
    "config = setting_config()\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "# -------- Data -------- #\n",
    "data_path = './data/ISIC2017/'\n",
    "\n",
    "train_dataset = isic_loader(path_Data=data_path, train=True)\n",
    "val_dataset = isic_loader(path_Data=data_path, train=False)\n",
    "test_dataset = isic_loader(path_Data=data_path, train=False, Test=True)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True, num_workers=config.num_workers)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False, num_workers=config.num_workers)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=config.num_workers)\n",
    "\n",
    "# -------- Model -------- #\n",
    "model = UCM_NetV2(1, 3, False)\n",
    "\n",
    "# -------- Load checkpoint -------- #\n",
    "state_dict = torch.load('results/fine70/ultra__Friday_11_July_2025_12h_28m_08s/checkpoints_GT_BceDiceLoss_new2/best.pth')\n",
    "new_state_dict = {k[len('module.'):] if k.startswith('module.') else k: v for k, v in state_dict.items()}\n",
    "model.load_state_dict(new_state_dict)\n",
    "\n",
    "\n",
    "\n",
    "# -------- Wrap with DataParallel and move to device -------- #\n",
    "model = torch.nn.DataParallel(model.to(device), device_ids=gpu_ids, output_device=gpu_ids[0] if gpu_ids else None)\n",
    "\n",
    "# -------- Training Setup -------- #\n",
    "criterion = GT_BceDiceLoss_new2().to(device)\n",
    "optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()),   lr=2e-4, weight_decay=config.weight_decay)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=30, eta_min=1e-6)\n",
    "\n",
    "scaler = torch.cuda.amp.GradScaler() if config.amp else None\n",
    "\n",
    "# -------- Logger -------- #\n",
    "log_dir = os.path.join(config.work_dir, 'log')\n",
    "checkpoint_dir = os.path.join(config.work_dir, 'fine_tune_checkpoints')\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "logger = get_logger('fine_tune', log_dir)\n",
    "\n",
    "# -------- Fine-tuning Loop -------- #\n",
    "best_dice = 0.0\n",
    "best_se = 0.0\n",
    "min_loss=float('inf')\n",
    "start_epoch = 1\n",
    "num_fine_tune_epochs = 30\n",
    "\n",
    "# --- Initial test before training ---\n",
    "test_loss, test_metrics = test_one_epoch(\n",
    "    test_loader, model, criterion, logger, config,\n",
    "    epoch=start_epoch, epoch_num=num_fine_tune_epochs\n",
    ")\n",
    "print(f\"Initial Test - Loss: {test_loss:.4f}, Dice: {test_metrics['f1']:.4f}, Sensitivity: {test_metrics['se']:.4f}\")\n",
    "\n",
    "for epoch in range(start_epoch, start_epoch + num_fine_tune_epochs):\n",
    "    print(f\"\\nüî• Fine-tuning Epoch {epoch}/{start_epoch + num_fine_tune_epochs - 1}\")\n",
    "\n",
    "    # Train\n",
    "    train_one_epoch(train_loader, model, criterion, optimizer, scheduler, epoch,\n",
    "                    logger, config, scaler=scaler, epoch_num=num_fine_tune_epochs)\n",
    "\n",
    "    # Validate\n",
    "    val_loss, val_metrics = val_one_epoch(val_loader, model, criterion, epoch,\n",
    "                                          logger, config, epoch_num=num_fine_tune_epochs)\n",
    "\n",
    "    # Test\n",
    "\n",
    "\n",
    "    # Extract validation metrics\n",
    "    dice_score = val_metrics['f1']\n",
    "    sensitivity = val_metrics['se']\n",
    "\n",
    "    # Print metrics\n",
    "    print(f\"Validation - Loss: {val_loss:.4f}, Dice: {dice_score:.4f}, Sensitivity: {sensitivity:.4f}\")\n",
    "    print(f\"Test       - Loss: {test_loss:.4f}, Dice: {test_metrics['f1']:.4f}, Sensitivity: {test_metrics['se']:.4f}\")\n",
    "    if val_loss < min_loss:\n",
    "            min_loss = val_loss\n",
    "            print(f\"‚úÖ New minimum validation loss: {val_loss:.4f} ‚Äî model saved.\")\n",
    "            torch.save(model.module.state_dict(), os.path.join(checkpoint_dir, 'fine_tuned_min_loss.pth'))\n",
    "\n",
    "            # Run test after improvement\n",
    "            test_loss, test_metrics = test_one_epoch(test_loader, model, criterion, logger,\n",
    "                                                     config, epoch=epoch, epoch_num=num_fine_tune_epochs)\n",
    "            print(f\"Test (best) - Loss: {test_loss:.4f}, Dice: {test_metrics['f1']:.4f}, Sensitivity: {test_metrics['se']:.4f}\")\n"
   ],
   "id": "4fc3d8852c7b1b9f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "pr",
   "id": "3577437f9b964a58"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "g",
   "id": "6ce15b396f04c165"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "f655f9b208a6776c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ===== SAFE LOOKAHEAD WRAPPER =====\n",
    "merged_data=np.load('merged_data2018.npy')\n",
    "merged_mask=np.load('merged_mask2018.npy')\n",
    "print(merged_data.shape)\n",
    "k=5\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "# ===== SETUP =====\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "gpu_ids = [0] if torch.cuda.is_available() else []\n",
    "\n",
    "config = setting_config()\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# === Load original ISIC2017 test set (not part of merged data) ===\n",
    "isic2017_test_dataset = isic_loader(path_Data='./data/ISIC2018/', train=False, Test=True)\n",
    "isic2017_test_loader = DataLoader(isic2017_test_dataset, batch_size=1, shuffle=False, num_workers=config.num_workers)\n",
    "\n",
    "# === Split merged dataset into train_val (1400) and test (600) ===\n",
    "train_val_data, test_data, train_val_mask, test_mask = train_test_split(\n",
    "    merged_data, merged_mask, test_size=600, random_state=42)\n",
    "\n",
    "test_set = ISICKFoldDataset(test_data, test_mask, train=False)\n",
    "test_loader = DataLoader(test_set, batch_size=1, shuffle=False, num_workers=config.num_workers)\n",
    "\n",
    "# === Manual 5-Fold with fixed 150-validation split ===\n",
    "num_folds = 5\n",
    "val_size = 150\n",
    "all_indices = np.arange(train_val_data.shape[0])\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(all_indices)\n",
    "\n",
    "folds = []\n",
    "for i in range(num_folds):\n",
    "    val_start = i * val_size\n",
    "    val_end = val_start + val_size\n",
    "    val_idx = all_indices[val_start:val_end]\n",
    "    train_idx = np.setdiff1d(all_indices, val_idx)\n",
    "    folds.append((train_idx, val_idx))\n",
    "\n",
    "# === Training Loop ===\n",
    "fold = 1\n",
    "for train_idx, val_idx in folds:\n",
    "    print(f\"\\n===== üîÅ Fold {fold}/{num_folds} =====\")\n",
    "\n",
    "    train_set = ISICKFoldDataset(train_val_data[train_idx], train_val_mask[train_idx], train=True)\n",
    "    val_set = ISICKFoldDataset(train_val_data[val_idx], train_val_mask[val_idx], train=False)\n",
    "\n",
    "    train_loader = DataLoader(train_set, batch_size=config.batch_size, shuffle=True, num_workers=config.num_workers)\n",
    "    val_loader = DataLoader(val_set, batch_size=1, shuffle=False, num_workers=config.num_workers)\n",
    "\n",
    "    model = UCM_NetV2(1, 3, False)\n",
    "    state_dict = torch.load('results/fine2018/checkpoints_GT_BceDiceLoss_new2/best.pth', map_location='cpu')\n",
    "    model.load_state_dict(state_dict)\n",
    "    model = torch.nn.DataParallel(model.to(device), device_ids=gpu_ids)\n",
    "\n",
    "    criterion = GT_BceDiceLoss_new2().to(device)\n",
    "    optimizer = AdamW(model.parameters(), lr=2e-4, weight_decay=config.weight_decay)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=30, eta_min=1e-6)\n",
    "    scaler = torch.cuda.amp.GradScaler() if config.amp else None\n",
    "\n",
    "    log_dir = os.path.join(config.work_dir, f'log_fold_{fold}')\n",
    "    checkpoint_dir = os.path.join(config.work_dir, f'checkpoints_fold_{fold}')\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    logger = get_logger(f'fold_{fold}', log_dir)\n",
    "\n",
    "    best_dice = 0.0\n",
    "    min_loss = float('inf')\n",
    "    start_epoch = 1\n",
    "    num_fine_tune_epochs = 15\n",
    "\n",
    "    for epoch in range(start_epoch, start_epoch + num_fine_tune_epochs):\n",
    "        print(f\"\\nüî• Fine-tuning Epoch {epoch}/{start_epoch + num_fine_tune_epochs - 1} (Fold {fold})\")\n",
    "\n",
    "        train_one_epoch(train_loader, model, criterion, optimizer, scheduler, epoch,\n",
    "                        logger, config, scaler=scaler, epoch_num=num_fine_tune_epochs)\n",
    "\n",
    "        val_loss, val_metrics = val_one_epoch(val_loader, model, criterion, epoch,\n",
    "                                              logger, config, epoch_num=num_fine_tune_epochs)\n",
    "\n",
    "        dice_score = val_metrics['f1']\n",
    "        sensitivity = val_metrics['se']\n",
    "\n",
    "        print(f\"Validation - Loss: {val_loss:.4f}, Dice: {dice_score:.4f}, Sensitivity: {sensitivity:.4f}\")\n",
    "\n",
    "        if val_loss < min_loss:\n",
    "            min_loss = val_loss\n",
    "            print(f\"‚úÖ New minimum validation loss: {val_loss:.4f} ‚Äî model saved.\")\n",
    "            torch.save(model.module.state_dict(), os.path.join(checkpoint_dir, 'fine_tuned_min_loss.pth'))\n",
    "\n",
    "            # Run test after improvement\n",
    "            test_loss, test_metrics = test_one_epoch(test_loader, model, criterion, logger,\n",
    "                                                     config, epoch=epoch, epoch_num=num_fine_tune_epochs)\n",
    "            print(f\"Test (best) - Loss: {test_loss:.4f}, Dice: {test_metrics['f1']:.4f}, Sensitivity: {test_metrics['se']:.4f}\")\n",
    "\n",
    "    fold += 1"
   ],
   "id": "ef87e6b5ffac328e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-20T23:17:06.447131Z",
     "start_time": "2025-07-20T23:15:33.099150Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ===== SAFE LOOKAHEAD WRAPPER =====\n",
    "merged_data=np.load('ph2_images.npy')\n",
    "merged_mask=np.load('ph2_masks.npy')\n",
    "print(merged_data.shape)\n",
    "k=5\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "# ===== SETUP =====\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "gpu_ids = [0] if torch.cuda.is_available() else []\n",
    "\n",
    "config = setting_config()\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# === Load original ISIC2017 test set (not part of merged data) ===\n",
    "\n",
    "\n",
    "# === Split merged dataset into train_val (1400) and test (600) ===\n",
    "# === Split merged dataset: 80% train_val, 20% test ===\n",
    "train_val_data, test_data, train_val_mask, test_mask = train_test_split(\n",
    "    merged_data, merged_mask, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "test_set = ISICKFoldDataset(test_data, test_mask, train=False)\n",
    "test_loader = DataLoader(test_set, batch_size=1, shuffle=False, num_workers=config.num_workers)\n",
    "\n",
    "# === Manual 5-Fold with fixed 150-validation split ===\n",
    "num_folds = 5\n",
    "val_size = 150\n",
    "all_indices = np.arange(train_val_data.shape[0])\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(all_indices)\n",
    "\n",
    "folds = []\n",
    "for i in range(num_folds):\n",
    "    val_start = i * val_size\n",
    "    val_end = val_start + val_size\n",
    "    val_idx = all_indices[val_start:val_end]\n",
    "    train_idx = np.setdiff1d(all_indices, val_idx)\n",
    "    folds.append((train_idx, val_idx))\n",
    "\n",
    "# === Training Loop ===\n",
    "for fold_idx, (train_idx, val_idx) in enumerate(folds, 1):\n",
    "    print(f\"\\n===== üîÅ Fold {fold_idx}/{num_folds} =====\")\n",
    "\n",
    "    # Reset metrics history for this fold\n",
    "    train_metrics_history = {'loss': [], 'f1': [], 'acc': [], 'se': [], 'sp': []}\n",
    "    val_metrics_history = {'loss': [], 'f1': [], 'acc': [], 'se': [], 'sp': []}\n",
    "    test_metrics_history = {'loss': [], 'f1': [], 'acc': [], 'se': [], 'sp': []}\n",
    "\n",
    "    train_set = ISICKFoldDataset(train_val_data[train_idx], train_val_mask[train_idx], train=True)\n",
    "    val_set = ISICKFoldDataset(train_val_data[val_idx], train_val_mask[val_idx], train=False)\n",
    "\n",
    "    train_loader = DataLoader(train_set, batch_size=config.batch_size, shuffle=True, num_workers=config.num_workers)\n",
    "    val_loader = DataLoader(val_set, batch_size=1, shuffle=False, num_workers=config.num_workers)\n",
    "\n",
    "    model = UCM_NetV2(1, 3, False)\n",
    "    state_dict = torch.load('results/fine70/ultra__Friday_11_July_2025_12h_28m_08s/checkpoints_GT_BceDiceLoss_new2/best.pth',\n",
    "                          map_location='cpu')\n",
    "    model.load_state_dict(state_dict)\n",
    "    model = torch.nn.DataParallel(model.to(device), device_ids=gpu_ids)\n",
    "\n",
    "    criterion = GT_BceDiceLoss_new2().to(device)\n",
    "    optimizer = AdamW(model.parameters(), lr=2e-4, weight_decay=config.weight_decay)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=30, eta_min=1e-6)\n",
    "    scaler = torch.cuda.amp.GradScaler() if config.amp else None\n",
    "\n",
    "    log_dir = os.path.join(config.work_dir, f'log_fold_{fold_idx}')\n",
    "    checkpoint_dir = os.path.join(config.work_dir, f'checkpoints_fold_{fold_idx}')\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    logger = get_logger(f'fold_{fold_idx}', log_dir)\n",
    "\n",
    "    best_dice = 0.0\n",
    "    min_loss = float('inf')\n",
    "    start_epoch = 1\n",
    "    num_fine_tune_epochs = 15\n",
    "\n",
    "    for epoch in range(start_epoch, start_epoch + num_fine_tune_epochs):\n",
    "        print(f\"\\nüî• Fine-tuning Epoch {epoch}/{start_epoch + num_fine_tune_epochs - 1} (Fold {fold_idx})\")\n",
    "\n",
    "        # Train\n",
    "        train_loss, train_metrics = train_one_epoch(train_loader, model, criterion, optimizer, scheduler,\n",
    "                                                   epoch, logger, config, scaler=scaler,\n",
    "                                                   epoch_num=num_fine_tune_epochs)\n",
    "        for key in train_metrics_history:\n",
    "            train_metrics_history[key].append(train_metrics[key] if key != 'loss' else train_loss)\n",
    "\n",
    "        # Validation\n",
    "        val_loss, val_metrics = val_one_epoch(val_loader, model, criterion, epoch,\n",
    "                                              logger, config, epoch_num=num_fine_tune_epochs)\n",
    "        for key in val_metrics_history:\n",
    "            val_metrics_history[key].append(val_metrics[key] if key != 'loss' else val_loss)\n",
    "\n",
    "        print(f\"Validation - Loss: {val_loss:.4f}, Dice: {val_metrics['f1']:.4f}, \"\n",
    "              f\"Sensitivity: {val_metrics['se']:.4f}\")\n",
    "\n",
    "        # Test\n",
    "        test_loss, test_metrics = test_one_epoch(test_loader, model, criterion, logger,\n",
    "                                                 config, epoch=epoch, epoch_num=num_fine_tune_epochs)\n",
    "        for key in test_metrics_history:\n",
    "            test_metrics_history[key].append(test_metrics[key] if key != 'loss' else test_loss)\n",
    "\n",
    "        print(f\"Test - Loss: {test_loss:.4f}, Dice: {test_metrics['f1']:.4f}, \"\n",
    "              f\"Sensitivity: {test_metrics['se']:.4f}\")\n",
    "\n",
    "        # Save best model\n",
    "        if val_loss < min_loss:\n",
    "            min_loss = val_loss\n",
    "            print(f\"‚úÖ New minimum validation loss: {val_loss:.4f} ‚Äî model saved.\")\n",
    "            torch.save(model.module.state_dict(),\n",
    "                      os.path.join(checkpoint_dir, 'fine_tuned_min_loss.pth'))\n"
   ],
   "id": "556cc016355725d0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 256, 256, 3)\n",
      "Using device: cuda\n",
      "\n",
      "===== üîÅ Fold 1/5 =====\n",
      "\n",
      "üî• Fine-tuning Epoch 1/15 (Fold 1)\n",
      "train: epoch 1, iter:0, loss: 3.0950, lr: 0.000200\n",
      "[Train] Epoch 1 | Loss: 2.5266 | Dice: 0.0000 | Acc: 0.5866 | SE: 0.0000 | SP: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 150/150 [00:02<00:00, 53.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val epoch: 1, loss: 2.9521, miou: 0.8315, f1_or_dsc: 0.9080, accuracy: 0.9422, specificity: 0.9620, sensitivity: 0.8996, confusion_matrix: [[6456353, 255126], [313282, 2805639]]\n",
      "0.9421785481769874 0.8315352453594063 0.8995543651150832 0.9619866202366182\n",
      "Validation - Loss: 2.9521, Dice: 0.9080, Sensitivity: 0.8996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:00<00:00, 62.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test of best model, loss: 1.4235,miou: 0.8442031309086003, f1_or_dsc: 0.9155207653212031, accuracy: 0.9462497711181641,                 specificity: 0.9584552075844114, sensitivity: 0.9199049129131445, confusion_matrix: [[1717038   74426]\n",
      " [  66477  763499]]\n",
      "Test - Loss: 1.4235, Dice: 0.9155, Sensitivity: 0.9199\n",
      "‚úÖ New minimum validation loss: 2.9521 ‚Äî model saved.\n",
      "\n",
      "üî• Fine-tuning Epoch 2/15 (Fold 1)\n",
      "train: epoch 2, iter:0, loss: 2.2018, lr: 0.000199\n",
      "[Train] Epoch 2 | Loss: 2.3146 | Dice: 0.0000 | Acc: 0.5976 | SE: 0.0000 | SP: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 150/150 [00:02<00:00, 60.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val epoch: 2, loss: 2.7009, miou: 0.8353, f1_or_dsc: 0.9103, accuracy: 0.9445, specificity: 0.9715, sensitivity: 0.8866, confusion_matrix: [[6520020, 191459], [353759, 2765162]]\n",
      "0.9445375569660497 0.835300479098824 0.886576479493746 0.971472904854359\n",
      "Validation - Loss: 2.7009, Dice: 0.9103, Sensitivity: 0.8866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:00<00:00, 61.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test of best model, loss: 1.3452,miou: 0.8508039420551775, f1_or_dsc: 0.9193885129836326, accuracy: 0.949612808227539,                 specificity: 0.9691040400476928, sensitivity: 0.9075419048261637, confusion_matrix: [[1736115   55349]\n",
      " [  76738  753238]]\n",
      "Test - Loss: 1.3452, Dice: 0.9194, Sensitivity: 0.9075\n",
      "‚úÖ New minimum validation loss: 2.7009 ‚Äî model saved.\n",
      "\n",
      "üî• Fine-tuning Epoch 3/15 (Fold 1)\n",
      "train: epoch 3, iter:0, loss: 2.3726, lr: 0.000198\n",
      "[Train] Epoch 3 | Loss: 1.9683 | Dice: 0.0000 | Acc: 0.5878 | SE: 0.0000 | SP: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 150/150 [00:02<00:00, 60.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val epoch: 3, loss: 2.5085, miou: 0.8356, f1_or_dsc: 0.9104, accuracy: 0.9452, specificity: 0.9769, sensitivity: 0.8772, confusion_matrix: [[6556279, 155200], [383074, 2735847]]\n",
      "0.945243937174383 0.835597401561874 0.8771773956439176 0.976875439824668\n",
      "Validation - Loss: 2.5085, Dice: 0.9104, Sensitivity: 0.8772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:00<00:00, 64.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test of best model, loss: 1.3031,miou: 0.8521270694535785, f1_or_dsc: 0.9201604830547357, accuracy: 0.950680160522461,                 specificity: 0.975244269491321, sensitivity: 0.8976596913645696, confusion_matrix: [[1747115   44349]\n",
      " [  84940  745036]]\n",
      "Test - Loss: 1.3031, Dice: 0.9202, Sensitivity: 0.8977\n",
      "‚úÖ New minimum validation loss: 2.5085 ‚Äî model saved.\n",
      "\n",
      "üî• Fine-tuning Epoch 4/15 (Fold 1)\n",
      "train: epoch 4, iter:0, loss: 1.7068, lr: 0.000195\n",
      "[Train] Epoch 4 | Loss: 2.5956 | Dice: 0.0000 | Acc: 0.5851 | SE: 0.0000 | SP: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 150/150 [00:02<00:00, 54.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val epoch: 4, loss: 2.3223, miou: 0.8382, f1_or_dsc: 0.9120, accuracy: 0.9463, specificity: 0.9790, sensitivity: 0.8760, confusion_matrix: [[6570647, 140832], [386623, 2732298]]\n",
      "0.9463445027668308 0.8381917280233079 0.8760395021224084 0.9790162496223292\n",
      "Validation - Loss: 2.3223, Dice: 0.9120, Sensitivity: 0.8760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:00<00:00, 52.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test of best model, loss: 1.2623,miou: 0.8555775037195622, f1_or_dsc: 0.9221684375937204, accuracy: 0.9520843505859375,                 specificity: 0.9778114436014343, sensitivity: 0.8965536352858396, confusion_matrix: [[1751714   39750]\n",
      " [  85858  744118]]\n",
      "Test - Loss: 1.2623, Dice: 0.9222, Sensitivity: 0.8966\n",
      "‚úÖ New minimum validation loss: 2.3223 ‚Äî model saved.\n",
      "\n",
      "üî• Fine-tuning Epoch 5/15 (Fold 1)\n",
      "train: epoch 5, iter:0, loss: 1.9152, lr: 0.000191\n",
      "[Train] Epoch 5 | Loss: 1.6070 | Dice: 0.0000 | Acc: 0.5839 | SE: 0.0000 | SP: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 150/150 [00:02<00:00, 64.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val epoch: 5, loss: 2.1386, miou: 0.8423, f1_or_dsc: 0.9144, accuracy: 0.9478, specificity: 0.9796, sensitivity: 0.8794, confusion_matrix: [[6574411, 137068], [376295, 2742626]]\n",
      "0.9477780151366223 0.8423326982981693 0.8793509037257182 0.9795770798059593\n",
      "Validation - Loss: 2.1386, Dice: 0.9144, Sensitivity: 0.8794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:00<00:00, 63.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test of best model, loss: 1.2160,miou: 0.8615707356051595, f1_or_dsc: 0.9256384612482427, accuracy: 0.9541362762451172,                 specificity: 0.9784829614214966, sensitivity: 0.9015851060753564, confusion_matrix: [[1752917   38547]\n",
      " [  81682  748294]]\n",
      "Test - Loss: 1.2160, Dice: 0.9256, Sensitivity: 0.9016\n",
      "‚úÖ New minimum validation loss: 2.1386 ‚Äî model saved.\n",
      "\n",
      "üî• Fine-tuning Epoch 6/15 (Fold 1)\n",
      "train: epoch 6, iter:0, loss: 1.7302, lr: 0.000187\n",
      "[Train] Epoch 6 | Loss: 1.2516 | Dice: 0.0000 | Acc: 0.5862 | SE: 0.0000 | SP: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 150/150 [00:02<00:00, 63.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val epoch: 6, loss: 1.9775, miou: 0.8460, f1_or_dsc: 0.9165, accuracy: 0.9490, specificity: 0.9799, sensitivity: 0.8825, confusion_matrix: [[6576664, 134815], [366414, 2752507]]\n",
      "0.949012349446518 0.8459527755168686 0.8825189865338422 0.9799127733244818\n",
      "Validation - Loss: 1.9775, Dice: 0.9165, Sensitivity: 0.8825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:00<00:00, 57.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test of best model, loss: 1.1768,miou: 0.8668252944023229, f1_or_dsc: 0.9286624699177789, accuracy: 0.9559108734130859,                 specificity: 0.9788530497961444, sensitivity: 0.9063912691451319, confusion_matrix: [[1753580   37884]\n",
      " [  77693  752283]]\n",
      "Test - Loss: 1.1768, Dice: 0.9287, Sensitivity: 0.9064\n",
      "‚úÖ New minimum validation loss: 1.9775 ‚Äî model saved.\n",
      "\n",
      "üî• Fine-tuning Epoch 7/15 (Fold 1)\n",
      "train: epoch 7, iter:0, loss: 1.5811, lr: 0.000181\n",
      "[Train] Epoch 7 | Loss: 1.2850 | Dice: 0.0000 | Acc: 0.5883 | SE: 0.0000 | SP: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 150/150 [00:02<00:00, 59.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val epoch: 7, loss: 1.8351, miou: 0.8496, f1_or_dsc: 0.9187, accuracy: 0.9502, specificity: 0.9799, sensitivity: 0.8863, confusion_matrix: [[6576522, 134957], [354469, 2764452]]\n",
      "0.9502130126952159 0.8495868621992436 0.8863488366647035 0.9798916155439091\n",
      "Validation - Loss: 1.8351, Dice: 0.9187, Sensitivity: 0.8863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:00<00:00, 61.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test of best model, loss: 1.1446,miou: 0.8715495819926801, f1_or_dsc: 0.9313668100256495, accuracy: 0.9574657440185547,                 specificity: 0.9787486658956027, sensitivity: 0.9115275622427637, confusion_matrix: [[1753393   38071]\n",
      " [  73430  756546]]\n",
      "Test - Loss: 1.1446, Dice: 0.9314, Sensitivity: 0.9115\n",
      "‚úÖ New minimum validation loss: 1.8351 ‚Äî model saved.\n",
      "\n",
      "üî• Fine-tuning Epoch 8/15 (Fold 1)\n",
      "train: epoch 8, iter:0, loss: 1.3862, lr: 0.000174\n",
      "[Train] Epoch 8 | Loss: 1.2136 | Dice: 0.0000 | Acc: 0.5840 | SE: 0.0000 | SP: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 150/150 [00:02<00:00, 61.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val epoch: 8, loss: 1.7115, miou: 0.8529, f1_or_dsc: 0.9206, accuracy: 0.9513, specificity: 0.9797, sensitivity: 0.8901, confusion_matrix: [[6575389, 136090], [342728, 2776193]]\n",
      "0.9512921142577158 0.8528981929705145 0.890113279560178 0.9797228002946922\n",
      "Validation - Loss: 1.7115, Dice: 0.9206, Sensitivity: 0.8901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:00<00:00, 63.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test of best model, loss: 1.1183,miou: 0.8753711453554304, f1_or_dsc: 0.9335444320164427, accuracy: 0.9587051391601562,                 specificity: 0.9784427708287747, sensitivity: 0.9161023933222165, confusion_matrix: [[1752845   38619]\n",
      " [  69633  760343]]\n",
      "Test - Loss: 1.1183, Dice: 0.9335, Sensitivity: 0.9161\n",
      "‚úÖ New minimum validation loss: 1.7115 ‚Äî model saved.\n",
      "\n",
      "üî• Fine-tuning Epoch 9/15 (Fold 1)\n",
      "train: epoch 9, iter:0, loss: 1.3033, lr: 0.000167\n",
      "[Train] Epoch 9 | Loss: 1.0479 | Dice: 0.0000 | Acc: 0.5840 | SE: 0.0000 | SP: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 150/150 [00:02<00:00, 59.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val epoch: 9, loss: 1.6080, miou: 0.8549, f1_or_dsc: 0.9218, accuracy: 0.9520, specificity: 0.9797, sensitivity: 0.8923, confusion_matrix: [[6575249, 136230], [335991, 2782930]]\n",
      "0.9519631958006843 0.8549311537311619 0.8922733214464579 0.979701940511029\n",
      "Validation - Loss: 1.6080, Dice: 0.9218, Sensitivity: 0.8923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:00<00:00, 60.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test of best model, loss: 1.1001,miou: 0.8776814502673108, f1_or_dsc: 0.9348566021593941, accuracy: 0.9594505310058594,                 specificity: 0.9782021854751198, sensitivity: 0.9189759703895053, confusion_matrix: [[1752414   39050]\n",
      " [  67248  762728]]\n",
      "Test - Loss: 1.1001, Dice: 0.9349, Sensitivity: 0.9190\n",
      "‚úÖ New minimum validation loss: 1.6080 ‚Äî model saved.\n",
      "\n",
      "üî• Fine-tuning Epoch 10/15 (Fold 1)\n",
      "train: epoch 10, iter:0, loss: 1.1378, lr: 0.000159\n",
      "[Train] Epoch 10 | Loss: 1.0262 | Dice: 0.0000 | Acc: 0.5883 | SE: 0.0000 | SP: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 150/150 [00:02<00:00, 64.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val epoch: 10, loss: 1.5208, miou: 0.8564, f1_or_dsc: 0.9226, accuracy: 0.9524, specificity: 0.9795, sensitivity: 0.8941, confusion_matrix: [[6573974, 137505], [330187, 2788734]]\n",
      "0.9524239095051115 0.8563787416017264 0.8941342214179538 0.9795119674812393\n",
      "Validation - Loss: 1.5208, Dice: 0.9226, Sensitivity: 0.8941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:00<00:00, 62.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test of best model, loss: 1.0861,miou: 0.8793578936114691, f1_or_dsc: 0.9358067418671923, accuracy: 0.9599666595458984,                 specificity: 0.9777215729704867, sensitivity: 0.9216435174029128, confusion_matrix: [[1751553   39911]\n",
      " [  65034  764942]]\n",
      "Test - Loss: 1.0861, Dice: 0.9358, Sensitivity: 0.9216\n",
      "‚úÖ New minimum validation loss: 1.5208 ‚Äî model saved.\n",
      "\n",
      "üî• Fine-tuning Epoch 11/15 (Fold 1)\n",
      "train: epoch 11, iter:0, loss: 1.0971, lr: 0.000150\n",
      "[Train] Epoch 11 | Loss: 0.8888 | Dice: 0.0000 | Acc: 0.5882 | SE: 0.0000 | SP: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 150/150 [00:02<00:00, 56.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val epoch: 11, loss: 1.4504, miou: 0.8572, f1_or_dsc: 0.9231, accuracy: 0.9527, specificity: 0.9793, sensitivity: 0.8954, confusion_matrix: [[6572339, 139140], [326086, 2792835]]\n",
      "0.9526747639972989 0.8572077072833022 0.895449099223451 0.9792683550077442\n",
      "Validation - Loss: 1.4504, Dice: 0.9231, Sensitivity: 0.8954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:00<00:00, 61.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test of best model, loss: 1.0759,miou: 0.8807937740330501, f1_or_dsc: 0.9366191936549578, accuracy: 0.9604072570800781,                 specificity: 0.9772811510585756, sensitivity: 0.9239857538049293, confusion_matrix: [[1750764   40700]\n",
      " [  63090  766886]]\n",
      "Test - Loss: 1.0759, Dice: 0.9366, Sensitivity: 0.9240\n",
      "‚úÖ New minimum validation loss: 1.4504 ‚Äî model saved.\n",
      "\n",
      "üî• Fine-tuning Epoch 12/15 (Fold 1)\n",
      "train: epoch 12, iter:0, loss: 0.9172, lr: 0.000141\n",
      "[Train] Epoch 12 | Loss: 1.0874 | Dice: 0.0000 | Acc: 0.5840 | SE: 0.0000 | SP: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 150/150 [00:02<00:00, 58.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val epoch: 12, loss: 1.3948, miou: 0.8579, f1_or_dsc: 0.9235, accuracy: 0.9529, specificity: 0.9788, sensitivity: 0.8970, confusion_matrix: [[6569295, 142184], [321273, 2797648]]\n",
      "0.952854715982976 0.8578834474814955 0.8969922611053961 0.9788148037115249\n",
      "Validation - Loss: 1.3948, Dice: 0.9235, Sensitivity: 0.8970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:00<00:00, 57.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test of best model, loss: 1.0682,miou: 0.8819920233724136, f1_or_dsc: 0.9372962397491338, accuracy: 0.9607547760009766,                 specificity: 0.9766554058580021, sensitivity: 0.926434017369177, confusion_matrix: [[1749643   41821]\n",
      " [  61058  768918]]\n",
      "Test - Loss: 1.0682, Dice: 0.9373, Sensitivity: 0.9264\n",
      "‚úÖ New minimum validation loss: 1.3948 ‚Äî model saved.\n",
      "\n",
      "üî• Fine-tuning Epoch 13/15 (Fold 1)\n",
      "train: epoch 13, iter:0, loss: 1.0578, lr: 0.000131\n",
      "[Train] Epoch 13 | Loss: 0.8043 | Dice: 0.0000 | Acc: 0.5923 | SE: 0.0000 | SP: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 150/150 [00:02<00:00, 62.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val epoch: 13, loss: 1.3530, miou: 0.8586, f1_or_dsc: 0.9239, accuracy: 0.9530, specificity: 0.9781, sensitivity: 0.8991, confusion_matrix: [[6564356, 147123], [314731, 2804190]]\n",
      "0.9530177815754238 0.8585891678125407 0.899089781369615 0.9780789003435788\n",
      "Validation - Loss: 1.3530, Dice: 0.9239, Sensitivity: 0.8991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:00<00:00, 63.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test of best model, loss: 1.0624,miou: 0.883007122529952, f1_or_dsc: 0.9378691264253637, accuracy: 0.9610134124755859,                 specificity: 0.9756679453229314, sensitivity: 0.9293822953916739, confusion_matrix: [[1747874   43590]\n",
      " [  58611  771365]]\n",
      "Test - Loss: 1.0624, Dice: 0.9379, Sensitivity: 0.9294\n",
      "‚úÖ New minimum validation loss: 1.3530 ‚Äî model saved.\n",
      "\n",
      "üî• Fine-tuning Epoch 14/15 (Fold 1)\n",
      "train: epoch 14, iter:0, loss: 0.9532, lr: 0.000121\n",
      "[Train] Epoch 14 | Loss: 0.9817 | Dice: 0.0000 | Acc: 0.5873 | SE: 0.0000 | SP: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 150/150 [00:02<00:00, 61.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val epoch: 14, loss: 1.3288, miou: 0.8590, f1_or_dsc: 0.9241, accuracy: 0.9531, specificity: 0.9777, sensitivity: 0.9002, confusion_matrix: [[6561709, 149770], [311208, 2807713]]\n",
      "0.9531068929035489 0.8589716801004259 0.9002193386748494 0.97768450143389\n",
      "Validation - Loss: 1.3288, Dice: 0.9241, Sensitivity: 0.9002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:00<00:00, 53.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test of best model, loss: 1.0594,miou: 0.8835426108923397, f1_or_dsc: 0.938171088652734, accuracy: 0.9611354827880859,                 specificity: 0.9749595861262074, sensitivity: 0.9312968085824168, confusion_matrix: [[1746605   44859]\n",
      " [  57022  772954]]\n",
      "Test - Loss: 1.0594, Dice: 0.9382, Sensitivity: 0.9313\n",
      "‚úÖ New minimum validation loss: 1.3288 ‚Äî model saved.\n",
      "\n",
      "üî• Fine-tuning Epoch 15/15 (Fold 1)\n",
      "train: epoch 15, iter:0, loss: 0.9998, lr: 0.000111\n",
      "[Train] Epoch 15 | Loss: 0.7483 | Dice: 0.0000 | Acc: 0.5879 | SE: 0.0000 | SP: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 150/150 [00:02<00:00, 58.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val epoch: 15, loss: 1.3227, miou: 0.8588, f1_or_dsc: 0.9241, accuracy: 0.9531, specificity: 0.9777, sensitivity: 0.9001, confusion_matrix: [[6561792, 149687], [311722, 2807199]]\n",
      "0.9530630493163093 0.85883623854532 0.9000545380915708 0.9776968683056331\n",
      "Validation - Loss: 1.3227, Dice: 0.9241, Sensitivity: 0.9001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:00<00:00, 59.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test of best model, loss: 1.0586,miou: 0.8835520580920163, f1_or_dsc: 0.9381764143933765, accuracy: 0.961117935180664,                 specificity: 0.9746994636788683, sensitivity: 0.9318028473112475, confusion_matrix: [[1746139   45325]\n",
      " [  56602  773374]]\n",
      "Test - Loss: 1.0586, Dice: 0.9382, Sensitivity: 0.9318\n",
      "‚úÖ New minimum validation loss: 1.3227 ‚Äî model saved.\n",
      "\n",
      "===== üîÅ Fold 2/5 =====\n",
      "\n",
      "üî• Fine-tuning Epoch 1/15 (Fold 2)\n",
      "train: epoch 1, iter:0, loss: 1.8896, lr: 0.000200\n",
      "[Train] Epoch 1 | Loss: 2.7842 | Dice: 0.0000 | Acc: 0.6919 | SE: 0.0000 | SP: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 60.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val epoch: 1, loss: 2.1436, miou: 0.8866, f1_or_dsc: 0.9399, accuracy: 0.9500, specificity: 0.9715, sensitivity: 0.9209, confusion_matrix: [[366263, 10754], [22030, 256313]]\n",
      "0.9499755859360505 0.8865986156864768 0.9208530482141787 0.9714760872826119\n",
      "Validation - Loss: 2.1436, Dice: 0.9399, Sensitivity: 0.9209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:00<00:00, 62.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test of best model, loss: 1.0681,miou: 0.8856423516760186, f1_or_dsc: 0.9393534790824268, accuracy: 0.9621925354003906,                 specificity: 0.9795189855894397, sensitivity: 0.9247942109169421, confusion_matrix: [[1754773   36691]\n",
      " [  62419  767557]]\n",
      "Test - Loss: 1.0681, Dice: 0.9394, Sensitivity: 0.9248\n",
      "‚úÖ New minimum validation loss: 2.1436 ‚Äî model saved.\n",
      "\n",
      "üî• Fine-tuning Epoch 2/15 (Fold 2)\n",
      "train: epoch 2, iter:0, loss: 1.7928, lr: 0.000199\n",
      "[Train] Epoch 2 | Loss: 2.2204 | Dice: 0.0000 | Acc: 0.6927 | SE: 0.0000 | SP: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 62.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val epoch: 2, loss: 1.9958, miou: 0.8997, f1_or_dsc: 0.9472, accuracy: 0.9551, specificity: 0.9607, sensitivity: 0.9476, confusion_matrix: [[362188, 14829], [14575, 263768]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9551330566391676 0.8997039280664603 0.9476365491463854 0.960667556102349\n",
      "Validation - Loss: 1.9958, Dice: 0.9472, Sensitivity: 0.9476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:00<00:00, 66.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test of best model, loss: 0.9948,miou: 0.906428612237902, f1_or_dsc: 0.9509179692533795, accuracy: 0.9687618255615235,                 specificity: 0.9747837522830489, sensitivity: 0.9557637811213818, confusion_matrix: [[1746290   45174]\n",
      " [  36715  793261]]\n",
      "Test - Loss: 0.9948, Dice: 0.9509, Sensitivity: 0.9558\n",
      "‚úÖ New minimum validation loss: 1.9958 ‚Äî model saved.\n",
      "\n",
      "üî• Fine-tuning Epoch 3/15 (Fold 2)\n",
      "train: epoch 3, iter:0, loss: 2.2889, lr: 0.000198\n",
      "[Train] Epoch 3 | Loss: 1.9670 | Dice: 0.0000 | Acc: 0.6929 | SE: 0.0000 | SP: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 52.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val epoch: 3, loss: 1.8500, miou: 0.9001, f1_or_dsc: 0.9474, accuracy: 0.9558, specificity: 0.9692, sensitivity: 0.9377, confusion_matrix: [[365405, 11612], [17341, 261002]]\n",
      "0.9558212280258853 0.9001465744653475 0.9376991697260657 0.969200327834105\n",
      "Validation - Loss: 1.8500, Dice: 0.9474, Sensitivity: 0.9377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:00<00:00, 57.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test of best model, loss: 0.9403,miou: 0.9112786767067391, f1_or_dsc: 0.9535801218448512, accuracy: 0.9707042694091796,                 specificity: 0.9801157042508251, sensitivity: 0.9503901317628461, confusion_matrix: [[1755842   35622]\n",
      " [  41175  788801]]\n",
      "Test - Loss: 0.9403, Dice: 0.9536, Sensitivity: 0.9504\n",
      "‚úÖ New minimum validation loss: 1.8500 ‚Äî model saved.\n",
      "\n",
      "üî• Fine-tuning Epoch 4/15 (Fold 2)\n",
      "train: epoch 4, iter:0, loss: 1.5891, lr: 0.000195\n",
      "[Train] Epoch 4 | Loss: 1.8129 | Dice: 0.0000 | Acc: 0.6922 | SE: 0.0000 | SP: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 55.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val epoch: 4, loss: 1.8497, miou: 0.8906, f1_or_dsc: 0.9421, accuracy: 0.9501, specificity: 0.9456, sensitivity: 0.9563, confusion_matrix: [[356494, 20523], [12165, 266178]]\n",
      "0.9501220703110502 0.8906265684256803 0.9562949310708144 0.9455647888531669\n",
      "Validation - Loss: 1.8497, Dice: 0.9421, Sensitivity: 0.9563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:00<00:00, 61.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test of best model, loss: 0.9635,miou: 0.9079272971635359, f1_or_dsc: 0.951742027605902, accuracy: 0.9690582275390625,                 specificity: 0.9715428275421666, sensitivity: 0.9636953357687451, confusion_matrix: [[1740484   50980]\n",
      " [  30132  799844]]\n",
      "Test - Loss: 0.9635, Dice: 0.9517, Sensitivity: 0.9637\n",
      "‚úÖ New minimum validation loss: 1.8497 ‚Äî model saved.\n",
      "\n",
      "üî• Fine-tuning Epoch 5/15 (Fold 2)\n",
      "train: epoch 5, iter:0, loss: 2.2159, lr: 0.000191\n",
      "[Train] Epoch 5 | Loss: 1.6535 | Dice: 0.0000 | Acc: 0.6927 | SE: 0.0000 | SP: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 57.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val epoch: 5, loss: 1.6310, miou: 0.8996, f1_or_dsc: 0.9472, accuracy: 0.9555, specificity: 0.9679, sensitivity: 0.9388, confusion_matrix: [[364903, 12114], [17037, 261306]]\n",
      "0.9555191040024482 0.899637467849287 0.9387913473630061 0.9678688228887082\n",
      "Validation - Loss: 1.6310, Dice: 0.9472, Sensitivity: 0.9388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:00<00:00, 64.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test of best model, loss: 0.9112,miou: 0.9133690495617645, f1_or_dsc: 0.9547233449511073, accuracy: 0.9714462280273437,                 specificity: 0.9809892914398504, sensitivity: 0.9508479763270263, confusion_matrix: [[1757407   34057]\n",
      " [  40795  789181]]\n",
      "Test - Loss: 0.9112, Dice: 0.9547, Sensitivity: 0.9508\n",
      "‚úÖ New minimum validation loss: 1.6310 ‚Äî model saved.\n",
      "\n",
      "üî• Fine-tuning Epoch 6/15 (Fold 2)\n",
      "train: epoch 6, iter:0, loss: 1.4016, lr: 0.000187\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[38], line 85\u001B[0m\n\u001B[0;32m     82\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124müî• Fine-tuning Epoch \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mstart_epoch\u001B[38;5;250m \u001B[39m\u001B[38;5;241m+\u001B[39m\u001B[38;5;250m \u001B[39mnum_fine_tune_epochs\u001B[38;5;250m \u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;241m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m (Fold \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfold_idx\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m)\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     84\u001B[0m \u001B[38;5;66;03m# Train\u001B[39;00m\n\u001B[1;32m---> 85\u001B[0m train_loss, train_metrics \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_one_epoch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscheduler\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     86\u001B[0m \u001B[43m                                           \u001B[49m\u001B[43mepoch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogger\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscaler\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mscaler\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[0;32m     87\u001B[0m \u001B[43m                                           \u001B[49m\u001B[43mepoch_num\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_fine_tune_epochs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     88\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m key \u001B[38;5;129;01min\u001B[39;00m train_metrics_history:\n\u001B[0;32m     89\u001B[0m     train_metrics_history[key]\u001B[38;5;241m.\u001B[39mappend(train_metrics[key] \u001B[38;5;28;01mif\u001B[39;00m key \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mloss\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m train_loss)\n",
      "File \u001B[1;32m~\\.conda\\envs\\jupyter_env\\UCMV2-Net-main\\UCMV2-Net-main\\engineucm1.py:53\u001B[0m, in \u001B[0;36mtrain_one_epoch\u001B[1;34m(train_loader, model, criterion, optimizer, scheduler, epoch, logger, config, scaler, epoch_num)\u001B[0m\n\u001B[0;32m     50\u001B[0m     loss\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[0;32m     51\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[1;32m---> 53\u001B[0m loss_list\u001B[38;5;241m.\u001B[39mappend(\u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mitem\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m     55\u001B[0m \u001B[38;5;66;03m# Collect predictions and targets for metrics\u001B[39;00m\n\u001B[0;32m     56\u001B[0m out \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39msigmoid(out)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 38
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (jupyter_env)",
   "language": "python",
   "name": "jupyter_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
